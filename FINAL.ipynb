{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer#ONLY USED FOR TRANSFORM FROM LANGUAGE TO VECTOR\n",
    "from numpy import linalg as LA\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (17,55,59,61,65,68,69,70,83,90,91,92,93,120,121,122,123,126,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Tab.delimited.Cleaned.dataset.WITH.variable.labels.csv', sep='\\t',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (1,11,12,19,20,129,132,169,230) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv('./ML3AllSites.csv', sep=',',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, n_h, n_iterate=10, learning_rate=1):\n",
    "        self.n_x = None  # size of the input layer\n",
    "        self.n_h = n_h  # size of the hidden layer\n",
    "        self.n_y = None # size of the output layer\n",
    "        self.W1 = None\n",
    "        self.W2 = None\n",
    "        self.b1 = None\n",
    "        self.b2 = None\n",
    "        self.A1 = None\n",
    "        self.A2 = None  # sigmoid output of the second activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterate = n_iterate\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        self.W1 = np.random.randn(self.n_h, self.n_x) * 0.01\n",
    "        self.b1 = np.zeros((self.n_h, 1))\n",
    "        self.W2 = np.random.randn(self.n_y, self.n_h) * 0.01\n",
    "        self.b2 = np.zeros((self.n_y, 1))\n",
    "\n",
    "    def relu(self, z):\n",
    "        return z * (z > 0)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def compute_cost(self, Y):\n",
    "        #cost = np.linalg.norm(self.A2 - Y)\n",
    "        cost = - (Y * np.log(self.A2) + (1-Y) * np.log(1-self.A2)).mean()\n",
    "        return np.squeeze(cost) \n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.A1 = self.relu(self.W1 @ X + self.b1)\n",
    "        self.A2 = self.sigmoid(self.W2 @ self.A1 + self.b2)\n",
    "\n",
    "    def backward_propagation(self, X, Y):\n",
    "        m = X.shape[1]\n",
    "\n",
    "        dZ2 = self.A2 - Y\n",
    "        dW2 = dZ2 @ self.A1.T / m\n",
    "        db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "        dZ1 = self.W2.T @ dZ2 * (self.A1 > 0)\n",
    "        dW1 = dZ1 @ X.T / m\n",
    "        db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        X, Y = X.T, Y.T\n",
    "        self.n_x = X.shape[0]\n",
    "        self.n_y = Y.shape[0]\n",
    "        self.initialize_parameters()\n",
    "\n",
    "        # gradient descent\n",
    "        for i in range(0, self.n_iterate):\n",
    "            self.forward_propagation(X)\n",
    "            self.backward_propagation(X, Y)\n",
    "            if i % 50 == 0:\n",
    "                cost = self.compute_cost(Y)\n",
    "                self.learning_rate = 5 * cost\n",
    "                print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.T\n",
    "        A1 = self.relu(self.W1 @ X + self.b1)\n",
    "        A2 = self.sigmoid(self.W2 @ A1 + self.b2)\n",
    "        return A2.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to perform kmeans clustering for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, n_clusters=64):\n",
    "        self.n_clusters = n_clusters  # number of clusters\n",
    "        self.centers = None  # to record the centers\n",
    "        self.labels = None\n",
    "        self.Y = None\n",
    "\n",
    "    def random_center(self):\n",
    "        # randomly generate n_cluster clusters in the raange of X\n",
    "        self.centers = np.random.rand(self.n_clusters, 3)\n",
    "        for j in range(3):\n",
    "            Y_j_min = self.Y[:,j].min()\n",
    "            Y_j_max = self.Y[:,j].max()\n",
    "            self.centers[:,j] = Y_j_min + (Y_j_max - Y_j_min) * self.centers[:,j]\n",
    "    \n",
    "    def random_center2(self,Y):\n",
    "    # randomly generate n_cluster clusters in the raange of X\n",
    "        self.centers = np.random.rand(self.n_clusters, len(Y[0]))\n",
    "        for i in range(self.n_clusters):\n",
    "            self.centers[i] = Y[i]\n",
    "#         for j in range(0):\n",
    "#             Y_j_min = self.Y[:,j].min()\n",
    "#             Y_j_max = self.Y[:,j].max()\n",
    "#             self.centers[:,j] = Y_j_min + (Y_j_max - Y_j_min) * self.centers[:,j]\n",
    "            \n",
    "            \n",
    "            \n",
    "    def dist(self, point1, point2): #old one\n",
    "        return 2*(point1[0]-point2[0])**2 + 4*(point1[1]-point2[1])**2 + 3*(point1[2]-point2[2])**2\n",
    "\n",
    "    def dist2(self,point1,point2):\n",
    "        return LA.norm(point1-point2)**2\n",
    "    \n",
    "\n",
    "    def fit(self, Y):\n",
    "        self.Y = Y\n",
    "        self.labels = np.zeros(Y.shape[0], dtype='uint8')  # record the current labels of each sample of X\n",
    "        self.random_center()\n",
    "        diff = 1\n",
    "\n",
    "        while diff > 1e-3:\n",
    "            old_center = self.centers.copy()\n",
    "\n",
    "            # go through all samples and label them using the nearest label\n",
    "            for i in range(Y.shape[0]):\n",
    "                distance = np.zeros(self.n_clusters)\n",
    "                for j in range(self.n_clusters):\n",
    "                    distance[j] = self.dist(Y[i], self.centers[j])\n",
    "                self.labels[i] = np.argmin(distance)\n",
    "                \n",
    "                \n",
    "            # update the centers\n",
    "            for i in range(self.n_clusters):\n",
    "                self.centers[i] = Y[self.labels==i].mean(axis=0)\n",
    "\n",
    "            # update the difference\n",
    "            diff = np.linalg.norm(self.centers - old_center)\n",
    "        return self\n",
    "    \n",
    "    def fit2(self, Y):\n",
    "        self.Y = Y\n",
    "        self.labels = np.zeros(Y.shape[0], dtype='uint8')  # record the current labels of each sample of X\n",
    "        self.random_center2(Y)\n",
    "        diff = 1\n",
    "        \n",
    "        while diff > 1e-3:\n",
    "            old_center = self.centers.copy()\n",
    "\n",
    "            # go through all samples and label them using the nearest label\n",
    "            for i in range(Y.shape[0]):\n",
    "                distance = np.zeros(self.n_clusters)\n",
    "                for j in range(self.n_clusters):\n",
    "                    distance[j] = self.dist2(Y[i], self.centers[j])\n",
    "                self.labels[i] = np.argmin(distance)\n",
    "                \n",
    "                \n",
    "            # update the centers\n",
    "            for i in range(self.n_clusters):\n",
    "                self.centers[i] = Y[self.labels==i].mean(axis=0)\n",
    "                \n",
    "\n",
    "            # update the difference\n",
    "            diff = np.linalg.norm(self.centers - old_center)\n",
    "            print(diff)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, Y):\n",
    "        out = np.zeros(Y.shape)\n",
    "        for i in range(self.n_clusters):\n",
    "            out[self.labels==i] = self.centers[i]\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oneHOTENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(Y, kmeans):\n",
    "    out = np.zeros((len(Y), kmeans.n_clusters))\n",
    "    for i in range(len(Y)):\n",
    "        out[i, Y[i]] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test clustering numbered data:\n",
    "    step1 : get single column\n",
    "    step2 : sort in increasing order\n",
    "    step3 : based on distribution, cut data into 4 section with equally number of candidate\n",
    "    step4 : if data is null, set isnon to be true for that column\n",
    "    step5 : append new datacol to input_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isint(value):\n",
    "  try:\n",
    "    int(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(value):\n",
    "  try:\n",
    "    isfloat(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdistriarr(df,arr_str):\n",
    "    arr = df[arr_str].values\n",
    "    di = []\n",
    "    di_og = []  #RETURN OG SINCE di will be sort\n",
    "    for i in range(len(arr)):\n",
    "        if isint(arr[i]) == True:\n",
    "            di.append(int(arr[i]))\n",
    "            di_og.append(int(arr[i]))\n",
    "        else:\n",
    "            di.append(-1)\n",
    "            di_og.append(-1)\n",
    "    di.sort()\n",
    "    ans_arr = []\n",
    "    leng = len(di)\n",
    "    ans_arr.append(di[int(leng/4)])\n",
    "    ans_arr.append(di[int(leng/2)])\n",
    "    ans_arr.append(di[int(leng*0.75)])\n",
    "    ans_arr.append(di[int(leng-1)])\n",
    "    return di_og,ans_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding_return_arr(att_arr,class_arr): #one \n",
    "    #add one more column for each row since last col used as flag\n",
    "    choice = len(class_arr)\n",
    "    out = np.zeros((len(att_arr),len(class_arr)+1))\n",
    "    for i in range(len(att_arr)):\n",
    "        loc = 0\n",
    "        #first jude if data is null\n",
    "        if att_arr[i] == -1:\n",
    "            out[i][-1] = 0\n",
    "            continue\n",
    "        else:\n",
    "            out[i][-1] = 1\n",
    "            for j in range(len(class_arr)):\n",
    "                if att_arr[i] < class_arr[j]:\n",
    "                    out[i][j] = 1\n",
    "                    break\n",
    "        \n",
    "    return out\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_ONE_HOT_ARRAY_ONLY_DIGIT_COLUMN(df,attr_name,og_dic):\n",
    "    att_arr,class_arr = getdistriarr(df,attr_name)\n",
    "    dic_ans = create_dic_for_classification(class_arr)\n",
    "    append_arr_of_dic_to_overall(og_dic,dic_ans,attr_name)\n",
    "    print(dic_ans)\n",
    "    return oneHotEncoding_return_arr(att_arr,class_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic_for_classification(class_arr):\n",
    "    cur_dic = {}\n",
    "    total_len = len(class_arr)\n",
    "    for i in range(len(class_arr)):\n",
    "        cur_dic[class_arr[i]] = i\n",
    "    return cur_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_arr_of_dic_to_overall(og,dic,att_name):\n",
    "    og[att_name] = dic\n",
    "    print(og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_arr(old,new):\n",
    "    #both old and new has the same num of row\n",
    "    #create a new nparray\n",
    "    \n",
    "    newdim = len(old[0])+len(new[0])\n",
    "    print('newdim is',newdim)\n",
    "    ans = np.zeros((len(old),newdim))\n",
    "    print(ans.shape)\n",
    "    for i in range(len(old)):\n",
    "        ans[i] = np.append(old[i],new[i])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP TWO CONVERT NLP DATASET INTO VECTOR:\n",
    "    STEP1: vectorize dataset\n",
    "    STEP2: apply kmeans clustering to language data\n",
    "    STEP3: ONEHOT ENCODING\n",
    "    STEP4: APPEND CLASSIFICATION DATASET INTO old CLASSFICAITION ARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLPDATAPRO(allsentences):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(allsentences)\n",
    "    ans = X.toarray()\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createtextarr_ONEHOT_ENCODING(attri_col): #ONEHOT_ENCODING\n",
    "    df2 = df[attri_col]\n",
    "    arr = df2.values\n",
    "    for i in range(len(arr)):\n",
    "        di.append(arr[i])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP THREE CONVERT TEXT_DATASET WITH FIXED classification into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processnull(arr):\n",
    "    arrnew = []\n",
    "    for i in range(len(arr)):\n",
    "        if type(arr[i]) == float and math.isnan(arr[i]) :\n",
    "            arrnew.append('Nan')\n",
    "        else:\n",
    "            arrnew.append(arr[i])\n",
    "    return arrnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnuniqiearr(og):\n",
    "    ar = np.asarray(og)\n",
    "    return np.unique(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: create a function to append text to old vecto(remember to append flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: TEST NN TONIGHT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onehoted_text_fixed_classification(attribu_name,df,km_num):\n",
    "    df_cur = df[attribu_name]\n",
    "    attribute_arr = df_cur.values\n",
    "    arr_no_null = processnull(attribute_arr) #create new arr with format fit by NLP(CountVectorizer)\n",
    "    NLP_ARR = NLPDATAPRO(arr_no_null)\n",
    "    #BEFORE ONEHOT_ENCODING\n",
    "    #APPLY KMEANS CLUSTERING SINCE TOO MANY DIFFERENT CLASSIFICATION\n",
    "    KM_TMP = KMeans(km_num)\n",
    "    KM_TMP.fit2(NLP_ARR)\n",
    "    labels_arr = KM_TMP.labels\n",
    "    return labels_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_enco(labelarr,df,att_name):\n",
    "    og_text_arr = df[att_name].values\n",
    "    #create dic to remeber loc for each value in the uniqe arr\n",
    "    uni_arr = np.unique(labelarr)\n",
    "    loc_dic = {}\n",
    "    for i in range(len(uni_arr)):\n",
    "        loc_dic[uni_arr[i]] = i\n",
    "    #based on the lenth of dic,create onehot_encod\n",
    "    choice = len(loc_dic)\n",
    "    out = np.zeros((len(labelarr),choice+1))\n",
    "    print('test dic',loc_dic)\n",
    "    for i in range(len(labelarr)):\n",
    "        #first junde if data is null\n",
    "        if type(og_text_arr[i])!=str and math.isnan(og_text_arr[i]) == True:\n",
    "            out[i][-1] = 0\n",
    "            continue\n",
    "        else:\n",
    "            out[i][-1] = 1\n",
    "            cur_loc = loc_dic.get(labelarr[i])\n",
    "            out[i][cur_loc] = 1\n",
    "            \n",
    "    return out,loc_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-62a42c2bed8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_enco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lowpower'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_arr' is not defined"
     ]
    }
   ],
   "source": [
    "out_arr = onehot_enco(labels_arr,df3,'lowpower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_ONE_HOT_ARRAY_ONLY_NLP_COLUMN(df,attr_name,og_dic,km_num):\n",
    "    labels_arr = create_onehoted_text_fixed_classification(attr_name,df,km_num)\n",
    "    out_arr,loc_dic = onehot_enco(labels_arr,df,attr_name)\n",
    "    #append dic to global array of dic\n",
    "    append_arr_of_dic_to_overall(og_dic,loc_dic,attr_name)\n",
    "    print(og_dic)\n",
    "    return out_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL WORK:\n",
    "    1. MAINTAIN AN ARRAY OF DICTIONARY S.T EVERY DIC\n",
    "       CONTAINS MAPPING FROM CLASSIFICAITON TO ACTUAL INDEX AFTER KMEANS\n",
    "    \n",
    "    2. AFTER TRAINING, WE WILL UTILIZED THE ARR_DIC TO RECOVER CANDIDATE ANSER\n",
    "    \n",
    "    3. TODO: REWRITE COST FUNCTION OF NERUAL NETWORK\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINDING:\n",
    "    AFTER combine several attributes column, num of candidate with dinct\n",
    "    ans grows extremly fast.\n",
    "    Need to apply Kmeans clustering again to the array of candidate before\n",
    "    threw into Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE A SCRIPT TO APPEND ASSIGNED ATTRIBUTE TO INPUT COLUMN\n",
    "\n",
    "(API)INSTRUCTION:<br>\n",
    "USER WHO WANTS TO CREATE PREPROCESSED DATASET ONLY NEED TO CREATE\n",
    "ARRAY[i]<br>\n",
    "       ARRAY[i][0] = 'name of attribute'<br>\n",
    "       ARRAY[i][1] = 1 : it is a digit column<br>\n",
    "       ARRAY[i][1] = 0 : it is a NLP column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_auto_append_attri(arr_of_attribute,df,og_dic):\n",
    "    for i in range(len(arr_of_attribute)):\n",
    "        name = arr_of_attribute[i][0]\n",
    "        isdigit = arr_of_attribute[i][1]\n",
    "        if isdigit == 1:\n",
    "            attr_arr = GET_ONE_HOT_ARRAY_ONLY_DIGIT_COLUMN(df,name,og_dic)\n",
    "        else:\n",
    "            attr_arr = GET_ONE_HOT_ARRAY_ONLY_NLP_COLUMN(df,name,og_dic,20)\n",
    "        #append old with new\n",
    "        print('cur att shape is',attr_arr.shape)\n",
    "        if i == 0:\n",
    "            old = attr_arr\n",
    "        else:\n",
    "            old = append_arr(old,attr_arr)\n",
    "            print(old.shape)\n",
    "    return old\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Kmeans Clustering to the overal column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_whole_attribute_get_Y_for_Neural_NetWork(X,num_cluster):\n",
    "    km = KMeans(num_cluster)\n",
    "    km.fit2(X)\n",
    "    \n",
    "    #APPLY ONEHOT_ENCODING TO NEURAL_NETWORKAGAIN\n",
    "    \n",
    "    return oneHotEncoding(km.labels,km),km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY NEURAL NETWORK TO SOLVE THIS QUESTION:\n",
    "\n",
    "REMEBER TO CONSIDER FLAG FOR EACH COLUMN\n",
    "\n",
    "# QUESTION: SHOULD I APPLY ONE HOT ENCODING TO EVERY ATTRIBUT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create testing attribut arra\n",
    "arr = []\n",
    "og_arr = []\n",
    "og = {} #init global dictionary\n",
    "arr.append(['age',1])\n",
    "arr.append(['mood_01',1]) #Today I generally feel\n",
    "arr.append(['major',0])\n",
    "arr.append(['big5_01',1]) #I see myself as: Extraverted, enthusiastic.\n",
    "arr.append(['big5_02',1]) #I see myself as: Critical, quarrelsome.\n",
    "arr.append(['big5_03',1]) #I see myself as: Dependable, self-disciplined.\n",
    "arr.append(['big5_04',1]) #I see myself as: Anxious, easily upset.\n",
    "arr.append(['big5_05',1]) #I see myself as: Open to new experiences, complex.\n",
    "arr.append(['big5_06',1]) #I see myself as: Reserved, quiet.\n",
    "arr.append(['big5_07',1]) #I see myself as: Sympathetic, warm.\n",
    "arr.append(['big5_08',1]) #I see myself as: Disorganized, careless.\n",
    "arr.append(['big5_09',1]) #I see myself as: Calm, emotionally stable.\n",
    "arr.append(['big5_10',1]) #I see myself as: Conventional, uncreative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': {18: 1, 19: 2, 149: 3}}\n",
      "{18: 1, 19: 2, 149: 3}\n",
      "cur att shape is (2998, 5)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}}\n",
      "{2: 1, 4: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 10\n",
      "(2998, 10)\n",
      "(2998, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:79: RuntimeWarning: Mean of empty slice.\n",
      "/usr/lib/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "test dic {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}}\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}}\n",
      "cur att shape is (2998, 10)\n",
      "newdim is 20\n",
      "(2998, 20)\n",
      "(2998, 20)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}}\n",
      "{2: 0, 5: 1, 6: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 25\n",
      "(2998, 25)\n",
      "(2998, 25)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}}\n",
      "{2: 0, 3: 1, 5: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 30\n",
      "(2998, 30)\n",
      "(2998, 30)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}}\n",
      "{4: 0, 6: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 35\n",
      "(2998, 35)\n",
      "(2998, 35)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}, 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3}}\n",
      "{1: 0, 3: 1, 5: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 40\n",
      "(2998, 40)\n",
      "(2998, 40)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}, 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3}, 'big5_05': {4: 0, 5: 1, 6: 2, 7: 3}}\n",
      "{4: 0, 5: 1, 6: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 45\n",
      "(2998, 45)\n",
      "(2998, 45)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}, 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3}, 'big5_05': {4: 0, 5: 1, 6: 2, 7: 3}, 'big5_06': {1: 0, 4: 1, 5: 2, 7: 3}}\n",
      "{1: 0, 4: 1, 5: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 50\n",
      "(2998, 50)\n",
      "(2998, 50)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}, 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3}, 'big5_05': {4: 0, 5: 1, 6: 2, 7: 3}, 'big5_06': {1: 0, 4: 1, 5: 2, 7: 3}, 'big5_07': {4: 0, 6: 2, 7: 3}}\n",
      "{4: 0, 6: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 55\n",
      "(2998, 55)\n",
      "(2998, 55)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}, 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3}, 'big5_05': {4: 0, 5: 1, 6: 2, 7: 3}, 'big5_06': {1: 0, 4: 1, 5: 2, 7: 3}, 'big5_07': {4: 0, 6: 2, 7: 3}, 'big5_08': {1: 0, 2: 1, 4: 2, 7: 3}}\n",
      "{1: 0, 2: 1, 4: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 60\n",
      "(2998, 60)\n",
      "(2998, 60)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}, 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3}, 'big5_05': {4: 0, 5: 1, 6: 2, 7: 3}, 'big5_06': {1: 0, 4: 1, 5: 2, 7: 3}, 'big5_07': {4: 0, 6: 2, 7: 3}, 'big5_08': {1: 0, 2: 1, 4: 2, 7: 3}, 'big5_09': {3: 0, 5: 1, 6: 2, 7: 3}}\n",
      "{3: 0, 5: 1, 6: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 65\n",
      "(2998, 65)\n",
      "(2998, 65)\n",
      "{'age': {18: 1, 19: 2, 149: 3}, 'mood_01': {2: 1, 4: 2, 7: 3}, 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8}, 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3}, 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3}, 'big5_03': {4: 0, 6: 2, 7: 3}, 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3}, 'big5_05': {4: 0, 5: 1, 6: 2, 7: 3}, 'big5_06': {1: 0, 4: 1, 5: 2, 7: 3}, 'big5_07': {4: 0, 6: 2, 7: 3}, 'big5_08': {1: 0, 2: 1, 4: 2, 7: 3}, 'big5_09': {3: 0, 5: 1, 6: 2, 7: 3}, 'big5_10': {1: 0, 3: 1, 4: 2, 7: 3}}\n",
      "{1: 0, 3: 1, 4: 2, 7: 3}\n",
      "cur att shape is (2998, 5)\n",
      "newdim is 70\n",
      "(2998, 70)\n",
      "(2998, 70)\n"
     ]
    }
   ],
   "source": [
    "#DATA PREPROCESSING\n",
    "X = semi_auto_append_attri(arr,df3,og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:79: RuntimeWarning: Mean of empty slice.\n",
      "/usr/lib/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "y,kmeans  = cluster_whole_attribute_get_Y_for_Neural_NetWork(X,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2998, 100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(50,1000,5) #size of input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693068\n",
      "Cost after iteration 50: 0.044702\n",
      "Cost after iteration 100: 0.042793\n",
      "Cost after iteration 150: 0.042455\n",
      "Cost after iteration 200: 0.041816\n",
      "Cost after iteration 250: 0.041076\n",
      "Cost after iteration 300: 0.040568\n",
      "Cost after iteration 350: 0.040234\n",
      "Cost after iteration 400: 0.039942\n",
      "Cost after iteration 450: 0.039704\n",
      "Cost after iteration 500: 0.039484\n",
      "Cost after iteration 550: 0.039270\n",
      "Cost after iteration 600: 0.039060\n",
      "Cost after iteration 650: 0.038852\n",
      "Cost after iteration 700: 0.038648\n",
      "Cost after iteration 750: 0.038449\n",
      "Cost after iteration 800: 0.038256\n",
      "Cost after iteration 850: 0.038079\n",
      "Cost after iteration 900: 0.037920\n",
      "Cost after iteration 950: 0.037783\n"
     ]
    }
   ],
   "source": [
    "nn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predicted_data(pred,kmeans):\n",
    "    ans = []\n",
    "    for i in range(len(pred)):\n",
    "        ans.append(kmeans.centers[np.argmax(pred[i])])\n",
    "    newarr = np.asarray(ans)\n",
    "    return newarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = nn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_after = process_predicted_data(ans,kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-164-1ab8de96a7d1>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-164-1ab8de96a7d1>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for i in range(len(pred)):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def find_classification_based_on_distance(pred,dic):\n",
    "    #create array with all dict keys based on insertion order\n",
    "    dicarr = list(dic.keys())\n",
    "    #isolate target awated_array used to classification\n",
    "    for i in range(len(pred)):\n",
    "        cur_loc = 0\n",
    "        cur_des = 0\n",
    "        for j in range(len(dicarr)):\n",
    "            cur_dict_key = dicarr[i]\n",
    "            cur_dict_arr = dic.get(cur_dict_key)\n",
    "            cur_dict_lengh = len(cur_dict_arr)+2\n",
    "            cur_des += cur_dict_lengh  #update current cutting position\n",
    "            #restore dimension of onehotencoding for current dictionary\n",
    "            one_hot_cur_dic = np.zeros((cur_dict_lengh,cur_dict_lengh))\n",
    "            for i in range(0,cur_dict_lengh-1):\n",
    "                one_hot_cur_dic[i][i] = 1\n",
    "                one_hot_cur_dic[i][-1] = 1\n",
    "            #isolate target awaited_classification array\n",
    "            cur_isolated_arr = pred[i][cur_loc:cur_des]\n",
    "            #compute classification with smallest distance\n",
    "            arr_store_distance= []\n",
    "            for i in range (len(one_hot_cur_dic)):\n",
    "                arr_store_distance.append(append(np.linalg.norm(cur_isolated_arr_arr-one_hot_cur_dic[i])))\n",
    "            #transfer dic to arr s.t unilized argmim\n",
    "            dis_np_array = np.asarray(arr_store_distance)\n",
    "            index = np.argmin(dis_np_array)\n",
    "            # change value in output array\n",
    "            for i range(one_hot_cur_dic[index]):\n",
    "                pred[cur_loc+i] = one_hot_cur_dic[i]\n",
    "\n",
    "            cur_loc += cur_dict_lengh #update cur_loc not used in curretn loop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': {18: 1, 19: 2, 149: 3},\n",
       " 'mood_01': {2: 1, 4: 2, 7: 3},\n",
       " 'major': {0: 0, 2: 1, 4: 2, 6: 3, 7: 4, 9: 5, 12: 6, 13: 7, 17: 8},\n",
       " 'big5_01': {2: 0, 5: 1, 6: 2, 7: 3},\n",
       " 'big5_02': {2: 0, 3: 1, 5: 2, 7: 3},\n",
       " 'big5_03': {4: 0, 6: 2, 7: 3},\n",
       " 'big5_04': {1: 0, 3: 1, 5: 2, 7: 3},\n",
       " 'big5_05': {4: 0, 5: 1, 6: 2, 7: 3},\n",
       " 'big5_06': {1: 0, 4: 1, 5: 2, 7: 3},\n",
       " 'big5_07': {4: 0, 6: 2, 7: 3},\n",
       " 'big5_08': {1: 0, 2: 1, 4: 2, 7: 3},\n",
       " 'big5_09': {3: 0, 5: 1, 6: 2, 7: 3},\n",
       " 'big5_10': {1: 0, 3: 1, 4: 2, 7: 3}}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['age', 'mood_01', 'major', 'big5_01', 'big5_02', 'big5_03', 'big5_04', 'big5_05', 'big5_06', 'big5_07', 'big5_08', 'big5_09', 'big5_10'])\n"
     ]
    }
   ],
   "source": [
    "print(og.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = list(og.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'mood_01',\n",
       " 'major',\n",
       " 'big5_01',\n",
       " 'big5_02',\n",
       " 'big5_03',\n",
       " 'big5_04',\n",
       " 'big5_05',\n",
       " 'big5_06',\n",
       " 'big5_07',\n",
       " 'big5_08',\n",
       " 'big5_09',\n",
       " 'big5_10']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{18: 1, 19: 2, 149: 3}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og.get('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(og.get('age'))+2 #totall lengh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70,)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = X[2][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((5,5))\n",
    "for i in range(0,4):\n",
    "    a[i][i] = 1\n",
    "    a[i][-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = []\n",
    "for i in range(len(a)):\n",
    "    dis.append(np.linalg.norm(a[i]-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.asarray(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4142135623730951,\n",
       " 1.4142135623730951,\n",
       " 1.4142135623730951,\n",
       " 0.0,\n",
       " 1.4142135623730951]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
